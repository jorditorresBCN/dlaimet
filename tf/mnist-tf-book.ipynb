{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"A very simple MNIST classifier.\n",
    "\n",
    "See extensive documentation at\n",
    "https://www.tensorflow.org/get_started/mnist/beginners\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Import complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "FLAGS = None\n",
    "\n",
    "TRAINING_SET = 60000\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.01\n",
    "N_EPOCHS = 3\n",
    "N_ITERATIONS = int(TRAINING_SET/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TensorBoard activation\n",
    "tensorboard_dir = \"tb/run1\"\n",
    "tensorboard_active = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model definition\n",
    "def model(x):\n",
    "    x2 = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    tf.summary.image(\"images\", x2)\n",
    "    net = tf.layers.conv2d(x2, 20, [5, 5], activation=tf.nn.relu)\n",
    "    net = tf.layers.max_pooling2d(net, [2, 2], [2, 2])\n",
    "    net = tf.layers.conv2d(net, 50, [5, 5], activation=tf.nn.relu)\n",
    "    net = tf.layers.max_pooling2d(net, [2, 2], [2, 2])\n",
    "    net = tf.contrib.layers.flatten(net)\n",
    "    net = tf.layers.dense(net, 500, activation=tf.nn.relu)\n",
    "    return tf.layers.dense(net, 10)\n",
    "print(\"Model defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get loss function\n",
    "def get_loss(y_, y):\n",
    "    with tf.name_scope('cross_entropy'):\n",
    "        diff = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y)\n",
    "        with tf.name_scope('total'):\n",
    "            cross_entropy = tf.reduce_mean(diff)\n",
    "    tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "    return cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get optimizer and accuracy functions\n",
    "def get_train_step(cross_entropy):\n",
    "    with tf.name_scope('train'):\n",
    "        train_step = tf.train.AdadeltaOptimizer(learning_rate=LEARNING_RATE).minimize(cross_entropy)\n",
    "    return train_step\n",
    "\n",
    "\n",
    "def get_accuracy(y_, y):\n",
    "    with tf.name_scope('accuracy'):\n",
    "        with tf.name_scope('correct_prediction'):\n",
    "            correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "        with tf.name_scope('accuracy'):\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train function\n",
    "def train(mnist, sess, x, y_, accuracy, train_step, train_writer, test_writer, merged):\n",
    "    global_step = 0\n",
    "    for epochid in range(N_EPOCHS):\n",
    "        print(\"Running epoch %d ...\" % (epochid + 1))\n",
    "        for iterid in range(N_ITERATIONS):\n",
    "            percent = (100 * (iterid + 1)) / N_ITERATIONS\n",
    "            sys.stdout.write('\\r %.f%% (%d/%d) ' % (percent, (iterid + 1), N_ITERATIONS))\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size=BATCH_SIZE)\n",
    "            if tensorboard_active:\n",
    "                summary, _ = sess.run([merged, train_step], feed_dict={x: batch_xs, y_: batch_ys})\n",
    "                train_writer.add_summary(summary, global_step)\n",
    "            else:\n",
    "                sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "            global_step += 1\n",
    "\n",
    "        # Test trained model\n",
    "        if tensorboard_active:\n",
    "            acc, summary = sess.run([accuracy, merged], feed_dict={x: mnist.test.images,\n",
    "                                                                   y_: mnist.test.labels})\n",
    "            test_writer.add_summary(summary, global_step)\n",
    "        else:\n",
    "            acc = sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "        print(\" --> Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main function\n",
    "def main(_):\n",
    "    # Import data\n",
    "    mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)\n",
    "\n",
    "    # Create the model\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    y = model(x)\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "    cross_entropy = get_loss(y_, y)\n",
    "    train_step = get_train_step(cross_entropy)\n",
    "    accuracy = get_accuracy(y_, y)\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    if tensorboard_active:\n",
    "        merged = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter(tensorboard_dir + '/train',\n",
    "                                             sess.graph)\n",
    "        test_writer = tf.summary.FileWriter(tensorboard_dir + '/test')\n",
    "    tf.global_variables_initializer().run()\n",
    "    tf.local_variables_initializer().run()\n",
    "\n",
    "    train(mnist, sess, x, y_, accuracy, train_step, train_writer, test_writer, merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Run the program\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data_dir', type=str, default='/tmp/tensorflow/mnist/input_data',\n",
    "                        help='Directory for storing input data')\n",
    "    FLAGS, unparsed = parser.parse_known_args()\n",
    "    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
